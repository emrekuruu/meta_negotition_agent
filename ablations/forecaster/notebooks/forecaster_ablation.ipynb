{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec56a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Evaluation Results\n",
    "paths = {\n",
    "    'baseline': Path(\"forecaster_ablation_oracle_baseline.pkl\"),\n",
    "    'oracle_target': Path(\"forecaster_ablation_oracle_target.pkl\"),\n",
    "    'self_target': Path(\"forecaster_ablation_self_target.pkl\")\n",
    "}\n",
    "\n",
    "data = {}\n",
    "for key, path in paths.items():\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            data[key] = pickle.load(f)\n",
    "        print(f\"Loaded {path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {path} not found. Some plots may be empty.\")\n",
    "\n",
    "def merge_round_data(sources):\n",
    "    merged = {}\n",
    "    for source_key in sources:\n",
    "        if source_key in data:\n",
    "            # Extract round_by_round_data\n",
    "            if 'round_by_round_data' in data[source_key]:\n",
    "                rd = data[source_key]['round_by_round_data']\n",
    "                for mode, mode_data in rd.items():\n",
    "                    merged[mode] = mode_data\n",
    "    return merged\n",
    "\n",
    "# 1. VS ORACLE Dataset\n",
    "round_data_vs_oracle = merge_round_data(['baseline', 'oracle_target'])\n",
    "\n",
    "# 2. VS SELF Dataset\n",
    "round_data_vs_self = merge_round_data(['baseline', 'self_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uukghspf5z",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean MAPE data - remove values > 200 (likely division by zero issues)\n",
    "def clean_mape_data(round_data, threshold=200):\n",
    "    \"\"\"Remove MAPE values greater than threshold from the dataset.\"\"\"\n",
    "    cleaned_count = 0\n",
    "    for mode, mode_rounds in round_data.items():\n",
    "        for round_num, metrics in mode_rounds.items():\n",
    "            if 'mape' in metrics:\n",
    "                original_len = len(metrics['mape'])\n",
    "                metrics['mape'] = [v for v in metrics['mape'] if v is None or np.isnan(v) or v <= threshold]\n",
    "                cleaned_count += original_len - len(metrics['mape'])\n",
    "    return cleaned_count\n",
    "\n",
    "# Apply cleaning to both datasets\n",
    "cleaned_oracle = clean_mape_data(round_data_vs_oracle)\n",
    "cleaned_self = clean_mape_data(round_data_vs_self)\n",
    "\n",
    "print(f\"Removed {cleaned_oracle} MAPE values > 200 from vs_oracle dataset\")\n",
    "print(f\"Removed {cleaned_self} MAPE values > 200 from vs_self dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9dcd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(round_data, target_name, metric='rmse', ylabel='RMSE'):\n",
    "    if not round_data:\n",
    "        print(f\"No data for {target_name} ({metric})\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    colors = {\n",
    "        'Oracle': 'black',\n",
    "        'ClassicFrequency': 'blue',\n",
    "        'CUHK': 'red',\n",
    "        'Bayesian': 'green',\n",
    "        'WindowedFrequency': 'purple',\n",
    "        'ConflictBased': 'orange',\n",
    "        'StepwiseCOMB': 'brown',\n",
    "        'ExpectationCOMB': 'cyan'\n",
    "    }\n",
    "    \n",
    "    # Sort modes (Oracle first)\n",
    "    modes = sorted(list(round_data.keys()))\n",
    "    if 'Oracle' in modes:\n",
    "        modes.remove('Oracle')\n",
    "        modes.insert(0, 'Oracle')\n",
    "        \n",
    "    for mode in modes:\n",
    "        if mode == 'Oracle':\n",
    "             lbl = 'Oracle (Baseline)'\n",
    "        else:\n",
    "             lbl = mode\n",
    "             \n",
    "        mode_rounds = round_data[mode]\n",
    "        rounds = sorted(mode_rounds.keys())\n",
    "        means = []\n",
    "        stds = []\n",
    "        valid_rounds = []\n",
    "        \n",
    "        for r in rounds:\n",
    "            if metric in mode_rounds[r]:\n",
    "                vals = mode_rounds[r][metric]\n",
    "                # Clean data\n",
    "                vals = [v for v in vals if v is not None and not np.isnan(v)]\n",
    "                if vals:\n",
    "                    means.append(np.mean(vals))\n",
    "                    stds.append(np.std(vals))\n",
    "                    valid_rounds.append(r)\n",
    "        \n",
    "        if not valid_rounds:\n",
    "            continue\n",
    "            \n",
    "        means = np.array(means)\n",
    "        stds = np.array(stds)\n",
    "        \n",
    "        color = colors.get(mode, 'gray')\n",
    "        style = '--' if mode == 'Oracle' else '-'\n",
    "        width = 3 if mode == 'Oracle' else 1.5\n",
    "        alpha_fill = 0.1\n",
    "        \n",
    "        plt.plot(valid_rounds, means, label=lbl, color=color, linestyle=style, linewidth=width)\n",
    "        # plt.fill_between(valid_rounds, means - stds, means + stds, color=color, alpha=alpha_fill)\n",
    "\n",
    "    plt.title(f\"Forecaster Performance: {metric.upper()} vs {target_name.upper()}\", fontsize=16)\n",
    "    plt.xlabel(\"Negotiation Round\", fontsize=14)\n",
    "    plt.ylabel(ylabel, fontsize=14)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x9ooin5817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violinplots(round_data, target_name, metric='rmse', ylabel='RMSE', ylim=None):\n",
    "    if not round_data:\n",
    "        print(f\"No data for {target_name} ({metric})\")\n",
    "        return\n",
    "\n",
    "    # Aggregate all values across all rounds for each mode\n",
    "    aggregated_data = {}\n",
    "    for mode, mode_rounds in round_data.items():\n",
    "        all_values = []\n",
    "        for round_num in mode_rounds.keys():\n",
    "            if metric in mode_rounds[round_num]:\n",
    "                vals = mode_rounds[round_num][metric]\n",
    "                # Clean data\n",
    "                vals = [v for v in vals if v is not None and not np.isnan(v)]\n",
    "                all_values.extend(vals)\n",
    "        if all_values:\n",
    "            aggregated_data[mode] = all_values\n",
    "    \n",
    "    if not aggregated_data:\n",
    "        print(f\"No valid data for {target_name} ({metric})\")\n",
    "        return\n",
    "    \n",
    "    # Sort modes (Oracle first)\n",
    "    modes = sorted(list(aggregated_data.keys()))\n",
    "    if 'Oracle' in modes:\n",
    "        modes.remove('Oracle')\n",
    "        modes.insert(0, 'Oracle')\n",
    "    \n",
    "    # Prepare data for violin plot - create long format\n",
    "    plot_data = []\n",
    "    for mode in modes:\n",
    "        for value in aggregated_data[mode]:\n",
    "            label = 'Oracle (Baseline)' if mode == 'Oracle' else mode\n",
    "            plot_data.append({'Mode': label, 'Value': value, 'Mode_key': mode})\n",
    "    \n",
    "    df_plot = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # Color mapping\n",
    "    colors = {\n",
    "        'Oracle': 'black',\n",
    "        'ClassicFrequency': 'blue',\n",
    "        'CUHK': 'red',\n",
    "        'Bayesian': 'green',\n",
    "        'WindowedFrequency': 'purple',\n",
    "        'ConflictBased': 'orange',\n",
    "        'StepwiseCOMB': 'brown',\n",
    "        'ExpectationCOMB': 'cyan'\n",
    "    }\n",
    "    \n",
    "    # Create color palette in the right order\n",
    "    palette = [colors.get(mode, 'gray') for mode in modes]\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Create violin plot\n",
    "    ax = sns.violinplot(data=df_plot, x='Mode', y='Value', palette=palette, \n",
    "                        inner='box', linewidth=1.5, cut=0)\n",
    "    \n",
    "    # Highlight Oracle with different styling\n",
    "    for i, (patch, mode) in enumerate(zip(ax.collections[::2], modes)):  # Every other collection is a violin body\n",
    "        if mode == 'Oracle':\n",
    "            patch.set_alpha(0.8)\n",
    "            patch.set_edgecolor('black')\n",
    "            patch.set_linewidth(2)\n",
    "        else:\n",
    "            patch.set_alpha(0.6)\n",
    "    \n",
    "    plt.title(f\"Forecaster Performance Distribution: {metric.upper()} vs {target_name.upper()}\", fontsize=16)\n",
    "    plt.ylabel(ylabel, fontsize=14)\n",
    "    plt.xlabel(\"Forecaster Mode\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Set y-axis limits if provided\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o9pvmbddx6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violinplots_end_of_session(round_data, target_name, metric='rmse', ylabel='RMSE', ylim=None):\n",
    "    if not round_data:\n",
    "        print(f\"No data for {target_name} ({metric})\")\n",
    "        return\n",
    "\n",
    "    # Get only the last round data for each mode\n",
    "    end_session_data = {}\n",
    "    for mode, mode_rounds in round_data.items():\n",
    "        if mode_rounds:\n",
    "            # Find the maximum round number for this mode\n",
    "            max_round = max(mode_rounds.keys())\n",
    "            if max_round in mode_rounds and metric in mode_rounds[max_round]:\n",
    "                vals = mode_rounds[max_round][metric]\n",
    "                # Clean data\n",
    "                vals = [v for v in vals if v is not None and not np.isnan(v)]\n",
    "                if vals:\n",
    "                    end_session_data[mode] = vals\n",
    "    \n",
    "    if not end_session_data:\n",
    "        print(f\"No valid end-of-session data for {target_name} ({metric})\")\n",
    "        return\n",
    "    \n",
    "    # Sort modes (Oracle first)\n",
    "    modes = sorted(list(end_session_data.keys()))\n",
    "    if 'Oracle' in modes:\n",
    "        modes.remove('Oracle')\n",
    "        modes.insert(0, 'Oracle')\n",
    "    \n",
    "    # Prepare data for violin plot - create long format\n",
    "    plot_data = []\n",
    "    for mode in modes:\n",
    "        for value in end_session_data[mode]:\n",
    "            label = 'Oracle (Baseline)' if mode == 'Oracle' else mode\n",
    "            plot_data.append({'Mode': label, 'Value': value, 'Mode_key': mode})\n",
    "    \n",
    "    df_plot = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # Color mapping\n",
    "    colors = {\n",
    "        'Oracle': 'black',\n",
    "        'ClassicFrequency': 'blue',\n",
    "        'CUHK': 'red',\n",
    "        'Bayesian': 'green',\n",
    "        'WindowedFrequency': 'purple',\n",
    "        'ConflictBased': 'orange',\n",
    "        'StepwiseCOMB': 'brown',\n",
    "        'ExpectationCOMB': 'cyan'\n",
    "    }\n",
    "    \n",
    "    # Create color palette in the right order\n",
    "    palette = [colors.get(mode, 'gray') for mode in modes]\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Create violin plot\n",
    "    ax = sns.violinplot(data=df_plot, x='Mode', y='Value', palette=palette, \n",
    "                        inner='box', linewidth=1.5, cut=0)\n",
    "    \n",
    "    # Highlight Oracle with different styling\n",
    "    for i, (patch, mode) in enumerate(zip(ax.collections[::2], modes)):  # Every other collection is a violin body\n",
    "        if mode == 'Oracle':\n",
    "            patch.set_alpha(0.8)\n",
    "            patch.set_edgecolor('black')\n",
    "            patch.set_linewidth(2)\n",
    "        else:\n",
    "            patch.set_alpha(0.6)\n",
    "    \n",
    "    plt.title(f\"End-of-Session Forecaster Performance: {metric.upper()} vs {target_name.upper()}\", fontsize=16)\n",
    "    plt.ylabel(ylabel, fontsize=14)\n",
    "    plt.xlabel(\"Forecaster Mode\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Set y-axis limits if provided\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0068af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. RMSE vs Oracle\n",
    "plot_results(round_data_vs_oracle, \"Oracle (Actual Future)\", metric='rmse', ylabel='RMSE (Utility)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f06b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RMSE vs Self\n",
    "plot_results(round_data_vs_self, \"Self (Opponent Model Expectation)\", metric='rmse', ylabel='RMSE (Utility)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. MAPE vs Oracle\n",
    "plot_results(round_data_vs_oracle, \"Oracle (Actual Future)\", metric='mape', ylabel='MAPE (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ad26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. MAPE vs Self\n",
    "plot_results(round_data_vs_self, \"Self (Opponent Model Expectation)\", metric='mape', ylabel='MAPE (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "us06uzycwo",
   "metadata": {},
   "source": [
    "## Violin Plots\n",
    "\n",
    "The following violin plots show the distribution of forecaster performance across all negotiation rounds. Each violin displays:\n",
    "- **Width**: Probability density at each value (wider = more data points at that value)\n",
    "- **Inner box**: Interquartile range with median line\n",
    "- **Thin lines**: Whiskers extending to data extremes\n",
    "- **Shape**: Full distribution of the data (shows multimodality, skewness, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ct92gu4d5oe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin Plot 1: RMSE vs Oracle\n",
    "plot_violinplots(round_data_vs_oracle, \"Oracle (Actual Future)\", metric='rmse', ylabel='RMSE (Utility)', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vab2gqas1xr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin Plot 2: RMSE vs Self\n",
    "plot_violinplots(round_data_vs_self, \"Self (Opponent Model Expectation)\", metric='rmse', ylabel='RMSE (Utility)', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ks2z902ib6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin Plot 3: MAPE vs Oracle\n",
    "plot_violinplots(round_data_vs_oracle, \"Oracle (Actual Future)\", metric='mape', ylabel='MAPE (%)', ylim=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4gnm5xi0a5y",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin Plot 4: MAPE vs Self\n",
    "plot_violinplots(round_data_vs_self, \"Self (Opponent Model Expectation)\", metric='mape', ylabel='MAPE (%)', ylim=(0, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vhrivgbm37a",
   "metadata": {},
   "source": [
    "## Violin Plots - End of Session Only\n",
    "\n",
    "The following violin plots show the distribution of forecaster performance **only from the last round** of each negotiation session. This provides insight into how well each forecaster performs at the end of negotiations when the most information is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "siuhate6qdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-of-Session Violin Plot 1: RMSE vs Oracle\n",
    "plot_violinplots_end_of_session(round_data_vs_oracle, \"Oracle (Actual Future)\", metric='rmse', ylabel='RMSE (Utility)', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ok61z8ex9uj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-of-Session Violin Plot 2: RMSE vs Self\n",
    "plot_violinplots_end_of_session(round_data_vs_self, \"Self (Opponent Model Expectation)\", metric='rmse', ylabel='RMSE (Utility)', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3zlez7c69w5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-of-Session Violin Plot 3: MAPE vs Oracle\n",
    "plot_violinplots_end_of_session(round_data_vs_oracle, \"Oracle (Actual Future)\", metric='mape', ylabel='MAPE (%)', ylim=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yw90yt6mi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-of-Session Violin Plot 4: MAPE vs Self\n",
    "plot_violinplots_end_of_session(round_data_vs_self, \"Self (Opponent Model Expectation)\", metric='mape', ylabel='MAPE (%)', ylim=(0, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9eeb98",
   "metadata": {},
   "source": [
    "## Significance Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ccc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add parent directory to path to import significance_tests\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "\n",
    "from strategy.ablations.significance_tests import iterative_compare_models_per_metric, prepare_data\n",
    "\n",
    "def run_significance_analysis(name, df):\n",
    "    if df is None or df.empty:\n",
    "        print(f\"Skipping {name}: No data\")\n",
    "        return\n",
    "        \n",
    "    print(f\"\\nRunning significance tests for: {name}\")\n",
    "    \n",
    "    # Prepare for minimization (negate values)\n",
    "    test_df = df.copy()\n",
    "    if 'rmse' in test_df.columns:\n",
    "        test_df['rmse'] = test_df['rmse'].apply(lambda x: [-v for v in x])\n",
    "    if 'mape' in test_df.columns:\n",
    "        test_df['mape'] = test_df['mape'].apply(lambda x: [-v for v in x])\n",
    "        \n",
    "    results_df = iterative_compare_models_per_metric(test_df)\n",
    "    \n",
    "    output_file = f\"significance_{name}.xlsx\"\n",
    "    results_df.to_excel(output_file, index=False)\n",
    "    print(f\"Saved results to {output_file}\")\n",
    "    display(results_df) # For notebook display\n",
    "\n",
    "# Prepare all data\n",
    "all_rounds_vs_oracle = prepare_data(round_data_vs_oracle, False)\n",
    "all_rounds_vs_self = prepare_data(round_data_vs_self, False)\n",
    "end_session_vs_oracle = prepare_data(round_data_vs_oracle, True)\n",
    "end_session_vs_self = prepare_data(round_data_vs_self, True)\n",
    "\n",
    "# Run for all scenarios\n",
    "scenarios = {\n",
    "    \"end_session_vs_self\": end_session_vs_self,\n",
    "    \"end_session_vs_oracle\": end_session_vs_oracle,\n",
    "    \"all_rounds_vs_self\": all_rounds_vs_self,\n",
    "    \"all_rounds_vs_oracle\": all_rounds_vs_oracle\n",
    "}\n",
    "\n",
    "for name, df in scenarios.items():\n",
    "    run_significance_analysis(name, df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
